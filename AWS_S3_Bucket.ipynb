{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "be06b3ea-71ff-473e-9937-6752680a9ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install boto3\n",
    "import boto3\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2d5a8854-0efd-4655-94cd-560e71820def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'YOUR_ACCESS_KEY' and 'YOUR_SECRET_KEY' with your actual credentials\n",
    "access_key = 'AKIAVB3XJSAK7N7EY7JG'\n",
    "secret_key = 'YnsnQZ1LvK6/g7H5Y1ImWiuBlMppPER7eY6qnLSk'\n",
    "\n",
    "# Replace 'your-s3-bucket' with the name of your S3 bucket\n",
    "bucket_name = 's3practicebucketkaran'\n",
    "\n",
    "# Specify the AWS region\n",
    "region_name = 'us-east-1'  # Change to your desired AWS region\n",
    "\n",
    "# Create a session with your AWS credentials\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=access_key,\n",
    "    aws_secret_access_key=secret_key,\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "# Create an S3 client using the session\n",
    "s3_client = session.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e6595-5846-47eb-89b8-b937f75deeaa",
   "metadata": {},
   "source": [
    "### Uploading and Downloading the txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3d39fea2-da28-429f-92c3-63faeb3c4349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully to s3practicebucketkaran/goodmorning-file.txt\n"
     ]
    }
   ],
   "source": [
    "# Specify the local file path and the object key (destination in S3)\n",
    "local_file_path = 'D:\\Karan.Tak_Data\\OneDrive - Course5 Intelligence Limted\\Desktop\\Practice\\AWS_practice\\s3Bucket.txt'\n",
    "s3_object_key = 'goodmorning-file.txt'\n",
    "\n",
    "# Upload the file to S3\n",
    "try:\n",
    "    s3_client.upload_file(local_file_path, bucket_name, s3_object_key)\n",
    "    print(f\"File uploaded successfully to {bucket_name}/{s3_object_key}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error uploading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8be87105-c149-4479-92e7-23538e826216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3practicebucketkaran goodmorning-file.txt D:\\Karan.Tak_Data\\OneDrive - Course5 Intelligence Limted\\Desktop\\Practice\\AWS_practice\\downloaded_file.txt\n"
     ]
    }
   ],
   "source": [
    "print(bucket_name , s3_object_key,downloaded_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eea78d88-2713-4430-9785-8d0a5a04db23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully to D:\\Karan.Tak_Data\\OneDrive - Course5 Intelligence Limted\\Desktop\\Practice\\AWS_practice\\downloaded_file.txt\n"
     ]
    }
   ],
   "source": [
    "# Specify the local file path for downloading\n",
    "downloaded_file_path = \"D:\\Karan.Tak_Data\\OneDrive - Course5 Intelligence Limted\\Desktop\\Practice\\AWS_practice\\downloaded_file.txt\"\n",
    "\n",
    "# Download the file from S3\n",
    "try:\n",
    "    s3_client.download_file(bucket_name, s3_object_key, downloaded_file_path)\n",
    "    print(f\"File downloaded successfully to {downloaded_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6e9c0a1e-6f26-4c66-8af5-f1f210d12386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully to s3practicebucketkaran/salary_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Specify the local file path and the object key (destination in S3)\n",
    "csv_model_file_path = \"D:\\Karan.Tak_Data\\OneDrive - Course5 Intelligence Limted\\Desktop\\Practice\\AWS_practice\\Salary_dataset.xls\"\n",
    "model_s3_object_key = 'salary_dataset.csv'\n",
    "\n",
    "# Upload the file to S3\n",
    "try:\n",
    "    s3_client.upload_file(csv_model_file_path, bucket_name, model_s3_object_key)\n",
    "    print(f\"File uploaded successfully to {bucket_name}/{model_s3_object_key}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error uploading file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a990cd-92b0-4aa3-a235-869cb753edfb",
   "metadata": {},
   "source": [
    "### Uploading and Downloading the model by saving locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cf3c05c6-57db-4737-89f7-9306a35a8bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 44410271.37055973\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Download CSV from S3\n",
    "def download_csv_from_s3(bucket_name, model_s3_object_key, local_file_path):\n",
    "    s3_client.download_file(bucket_name, model_s3_object_key, local_file_path)\n",
    "\n",
    "# Step 2: Perform Model Evaluation and Building in Jupyter Notebook\n",
    "def train_and_evaluate_model(csv_path):\n",
    "    # Example: Load CSV and perform model-related operations\n",
    "    df = pd.read_csv(csv_path,index_col=0)\n",
    "    # print(df)\n",
    "    x = df.iloc[:,0:1]\n",
    "    y = df.iloc[:,1:2]\n",
    "    # Your model-related code here\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.5,random_state=2)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train,y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    # Evaluate the model using mean squared error (since it's a regression task)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    \n",
    "    # Step 3: Save Model to Local File\n",
    "    model_file_path = 'D:\\Karan.Tak_Data\\OneDrive - Course5 Intelligence Limted\\Desktop\\Practice\\AWS_practice\\model.pkl'\n",
    "    joblib.dump(model, model_file_path)\n",
    "\n",
    "    # Step 4: Upload Model File to S3\n",
    "    upload_model_to_s3(bucket_name, 'linear_salary_model', model_file_path)\n",
    "\n",
    "# Step 4 (continued): Upload Model File to S3\n",
    "def upload_model_to_s3(bucket_name, s3_object_key, local_model_path):\n",
    "    s3_client.upload_file(local_model_path, bucket_name, s3_object_key)\n",
    "\n",
    "model_s3_object_key = 'salary_dataset.csv'\n",
    "\n",
    "# Create a session with your AWS credentials\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=access_key,\n",
    "    aws_secret_access_key=secret_key,\n",
    "    region_name='us-east-1'  # Change to your desired AWS region\n",
    ")\n",
    "\n",
    "# Create an S3 client using the session\n",
    "s3_client = session.client('s3')\n",
    "\n",
    "# Step 1: Download CSV from S3\n",
    "model_csv_path = 'D:\\Karan.Tak_Data\\OneDrive - Course5 Intelligence Limted\\Desktop\\Practice\\AWS_practice\\salary_dataset.csv'\n",
    "download_csv_from_s3(bucket_name,model_s3_object_key, model_csv_path)\n",
    "\n",
    "# Step 2-4: Perform Model Evaluation and Building, Save Model, Upload Model\n",
    "train_and_evaluate_model(model_csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018ac9c4-b7ee-4dec-8ae7-aa45181d2db0",
   "metadata": {},
   "source": [
    "### Uploading and Downloading the model directly using cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6d4f1221-ff5e-4b70-8bc4-e37d73af54d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 44410271.37055973\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "from io import BytesIO\n",
    "\n",
    "# Step 1: Download CSV from S3\n",
    "def download_csv_from_s3(bucket_name, s3_object_key):\n",
    "    response = s3_client.get_object(Bucket=bucket_name, Key=s3_object_key)\n",
    "    df = pd.read_csv(BytesIO(response['Body'].read()), index_col=0)\n",
    "    return df\n",
    "\n",
    "# Step 2: Perform Model Evaluation and Building in Jupyter Notebook\n",
    "def train_and_evaluate_model(df):\n",
    "    x = df.iloc[:, 0:1]\n",
    "    y = df.iloc[:, 1:2]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=2)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "\n",
    "    # Evaluate the model using mean squared error (since it's a regression task)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "    # Step 3: Save Model to BytesIO buffer\n",
    "    model_buffer = BytesIO()\n",
    "    joblib.dump(model, model_buffer)\n",
    "    model_buffer.seek(0)\n",
    "\n",
    "    # Step 4: Upload Model File to S3\n",
    "    upload_model_to_s3(bucket_name, 'linear_salary_model', model_buffer)\n",
    "\n",
    "# Step 4 (continued): Upload Model File to S3\n",
    "def upload_model_to_s3(bucket_name, s3_object_key, model_buffer):\n",
    "    s3_client.upload_fileobj(model_buffer, bucket_name, s3_object_key)\n",
    "\n",
    "model_s3_object_key = 'salary_dataset.csv'\n",
    "\n",
    "# Create a session with your AWS credentials\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=access_key,\n",
    "    aws_secret_access_key=secret_key,\n",
    "    region_name='us-east-1'  # Change to your desired AWS region\n",
    ")\n",
    "\n",
    "# Create an S3 client using the session\n",
    "s3_client = session.client('s3')\n",
    "\n",
    "# Step 1: Download CSV from S3\n",
    "df = download_csv_from_s3(bucket_name, model_s3_object_key)\n",
    "\n",
    "# Step 2-4: Perform Model Evaluation and Building, Save Model, Upload Model\n",
    "train_and_evaluate_model(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a555b01-8092-414c-b13a-96a21b81944a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
